import numpy as np
import torch
import re
import string
from nltk.corpus import stopwords
import nltk
import asyncio
import logging
from aiogram import Bot, Dispatcher
from aiogram.filters import Command
from aiogram.types import Message
from transformers import ElectraTokenizer, ElectraForSequenceClassification
from dotenv import load_dotenv
import os

MAX_VOCAB_SIZE = 25000
MAX_SEQUENCE_LENGTH = 175

load_dotenv()

TOKEN = os.getenv("API_TOKEN")

logging.basicConfig(level=logging.INFO)

bot = Bot(token=TOKEN)
dp = Dispatcher()

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ELECTRA
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_name = "google/electra-small-discriminator"
model = ElectraForSequenceClassification.from_pretrained("./saved_model").to(device)
tokenizer = ElectraTokenizer.from_pretrained("./saved_model")


nltk.download("stopwords")
stop_words = set(stopwords.words("english"))

def preprocess_text(text):
    encoding = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors="pt").to(device)
    return encoding

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(Command("start"))
async def start_handler(message: Message):
    await message.answer(        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–µ–π–∫–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤.\n\n"
        "üîç –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞, –∏ —è —Å–∫–∞–∂—É, –Ω–∞—Å—Ç–æ—è—â–∏–π –æ–Ω –∏–ª–∏ –ø–æ–¥–¥–µ–ª—å–Ω—ã–π.\n\n"
        "üìå –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –æ—Ç–∑—ã–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏, –∏ —è —Å—Ä–∞–∑—É –µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é!"
    )

@dp.message(Command("help"))
async def send_help(message: Message):
    help_text = (
        "üÜò **–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º?**\n\n"
        "üîπ –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é, –Ω–∞—Å—Ç–æ—è—â–∏–π –æ–Ω –∏–ª–∏ —Ñ–µ–π–∫–æ–≤—ã–π.\n"
        "üîπ –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∏–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –æ—à–∏–±–∫–∏, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –µ–≥–æ.\n\n"
        "–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –Ω–∞–ø–∏—à–∏—Ç–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É. üòâ"
    )
    await message.answer(help_text, parse_mode="Markdown")

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
@dp.message()
async def classify_review(message: Message):
    text = message.text
    text_input = preprocess_text(text)

    with torch.no_grad():
        outputs = model(**text_input)
        prediction = torch.softmax(outputs.logits, dim=1)[:, 1].item()

    sentiment = "‚ùå –§–µ–π–∫–æ–≤—ã–π –æ—Ç–∑—ã–≤" if prediction < 0.5 else "‚úÖ –ù–∞—Å—Ç–æ—è—â–∏–π –æ—Ç–∑—ã–≤"
    await message.answer(sentiment)

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
